{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Phase 1: Check and Install Libraries/Dependecies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T14:13:49.434689Z",
     "iopub.status.busy": "2025-04-22T14:13:49.434388Z",
     "iopub.status.idle": "2025-04-22T14:13:49.563955Z",
     "shell.execute_reply": "2025-04-22T14:13:49.563198Z",
     "shell.execute_reply.started": "2025-04-22T14:13:49.434667Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:             x86_64\n",
      "  CPU op-mode(s):         32-bit, 64-bit\n",
      "  Address sizes:          46 bits physical, 48 bits virtual\n",
      "  Byte Order:             Little Endian\n",
      "CPU(s):                   4\n",
      "  On-line CPU(s) list:    0-3\n",
      "Vendor ID:                GenuineIntel\n",
      "  Model name:             Intel(R) Xeon(R) CPU @ 2.00GHz\n",
      "    CPU family:           6\n",
      "    Model:                85\n",
      "    Thread(s) per core:   2\n",
      "    Core(s) per socket:   2\n",
      "    Socket(s):            1\n",
      "    Stepping:             3\n",
      "    BogoMIPS:             4000.32\n",
      "    Flags:                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge m\n",
      "                          ca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht sysc\n",
      "                          all nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xt\n",
      "                          opology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq\n",
      "                           ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt\n",
      "                           aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dno\n",
      "                          wprefetch pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust\n",
      "                           bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f \n",
      "                          avx512dq rdseed adx smap clflushopt clwb avx512cd avx5\n",
      "                          12bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_c\n",
      "                          lear arch_capabilities\n",
      "Virtualization features:  \n",
      "  Hypervisor vendor:      KVM\n",
      "  Virtualization type:    full\n",
      "Caches (sum of all):      \n",
      "  L1d:                    64 KiB (2 instances)\n",
      "  L1i:                    64 KiB (2 instances)\n",
      "  L2:                     2 MiB (2 instances)\n",
      "  L3:                     38.5 MiB (1 instance)\n",
      "NUMA:                     \n",
      "  NUMA node(s):           1\n",
      "  NUMA node0 CPU(s):      0-3\n",
      "Vulnerabilities:          \n",
      "  Gather data sampling:   Not affected\n",
      "  Itlb multihit:          Not affected\n",
      "  L1tf:                   Mitigation; PTE Inversion\n",
      "  Mds:                    Mitigation; Clear CPU buffers; SMT Host state unknown\n",
      "  Meltdown:               Mitigation; PTI\n",
      "  Mmio stale data:        Vulnerable: Clear CPU buffers attempted, no microcode;\n",
      "                           SMT Host state unknown\n",
      "  Reg file data sampling: Not affected\n",
      "  Retbleed:               Mitigation; IBRS\n",
      "  Spec rstack overflow:   Not affected\n",
      "  Spec store bypass:      Mitigation; Speculative Store Bypass disabled via prct\n",
      "                          l\n",
      "  Spectre v1:             Mitigation; usercopy/swapgs barriers and __user pointe\n",
      "                          r sanitization\n",
      "  Spectre v2:             Mitigation; IBRS; IBPB conditional; STIBP conditional;\n",
      "                           RSB filling; PBRSB-eIBRS Not affected; BHI SW loop, K\n",
      "                          VM SW loop\n",
      "  Srbds:                  Not affected\n",
      "  Tsx async abort:        Mitigation; Clear CPU buffers; SMT Host state unknown\n"
     ]
    }
   ],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T14:13:49.565633Z",
     "iopub.status.busy": "2025-04-22T14:13:49.565335Z",
     "iopub.status.idle": "2025-04-22T14:15:17.073729Z",
     "shell.execute_reply": "2025-04-22T14:15:17.072999Z",
     "shell.execute_reply.started": "2025-04-22T14:13:49.565612Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-tsmixer\n",
      "  Downloading pytorch_tsmixer-0.2.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: torch>1.6 in /usr/local/lib/python3.11/dist-packages (from pytorch-tsmixer) (2.5.1+cu124)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>1.6->pytorch-tsmixer) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>1.6->pytorch-tsmixer) (4.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>1.6->pytorch-tsmixer) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>1.6->pytorch-tsmixer) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>1.6->pytorch-tsmixer) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>1.6->pytorch-tsmixer) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>1.6->pytorch-tsmixer) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>1.6->pytorch-tsmixer) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>1.6->pytorch-tsmixer)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>1.6->pytorch-tsmixer)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>1.6->pytorch-tsmixer)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>1.6->pytorch-tsmixer)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>1.6->pytorch-tsmixer)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>1.6->pytorch-tsmixer)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>1.6->pytorch-tsmixer) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>1.6->pytorch-tsmixer) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>1.6->pytorch-tsmixer)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>1.6->pytorch-tsmixer) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>1.6->pytorch-tsmixer) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>1.6->pytorch-tsmixer) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>1.6->pytorch-tsmixer) (3.0.2)\n",
      "Downloading pytorch_tsmixer-0.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-tsmixer\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-tsmixer-0.2.0\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.5->scikit-learn) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.5->scikit-learn) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.5->scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.5->scikit-learn) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.5->scikit-learn) (2024.2.0)\n",
      "Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.2\n",
      "    Uninstalling scikit-learn-1.2.2:\n",
      "      Successfully uninstalled scikit-learn-1.2.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.6.1 which is incompatible.\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed scikit-learn-1.6.1\n",
      "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.44.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from shap) (1.6.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from shap) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n",
      "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from shap) (24.2)\n",
      "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.7)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->shap) (0.43.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->shap) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->shap) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->shap) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->shap) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->shap) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->shap) (2.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->shap) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->shap) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->shap) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->shap) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->shap) (2024.2.0)\n",
      "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.2.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.2)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.38)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.9)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->optuna) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->optuna) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->optuna) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-tsmixer\n",
    "!pip install --upgrade scikit-learn imbalanced-learn\n",
    "!pip install shap\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T14:15:17.075075Z",
     "iopub.status.busy": "2025-04-22T14:15:17.074797Z",
     "iopub.status.idle": "2025-04-22T14:15:23.193004Z",
     "shell.execute_reply": "2025-04-22T14:15:23.192380Z",
     "shell.execute_reply.started": "2025-04-22T14:15:17.075046Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import pprint as pp\n",
    "from scipy.stats import skew\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, LabelEncoder\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchtsmixer import TSMixer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from torch.optim.lr_scheduler import OneCycleLR, ReduceLROnPlateau\n",
    "import shap\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T14:15:23.194765Z",
     "iopub.status.busy": "2025-04-22T14:15:23.194338Z",
     "iopub.status.idle": "2025-04-22T14:15:23.202817Z",
     "shell.execute_reply": "2025-04-22T14:15:23.202269Z",
     "shell.execute_reply.started": "2025-04-22T14:15:23.194745Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T14:15:23.203685Z",
     "iopub.status.busy": "2025-04-22T14:15:23.203478Z",
     "iopub.status.idle": "2025-04-22T14:15:24.542599Z",
     "shell.execute_reply": "2025-04-22T14:15:24.541907Z",
     "shell.execute_reply.started": "2025-04-22T14:15:23.203668Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Phase 2: Load & Clean Data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T14:15:24.543666Z",
     "iopub.status.busy": "2025-04-22T14:15:24.543355Z",
     "iopub.status.idle": "2025-04-22T14:15:32.754861Z",
     "shell.execute_reply": "2025-04-22T14:15:32.754164Z",
     "shell.execute_reply.started": "2025-04-22T14:15:24.543647Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All CSVs loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "# Binary Class\n",
    "x_scaled = pd.read_csv(\"/kaggle/input/toniotpreprocessed/StandardScaler/x_scaled_binary_pca_s.csv\").values\n",
    "y = pd.read_csv(\"/kaggle/input/toniotpreprocessed/StandardScaler/y_label_pca_s.csv\")[\"label\"].values  # Binary Classification\n",
    "\n",
    "# Multi-Class\n",
    "# x_scaled = pd.read_csv(\"/kaggle/input/ton-iot-preprocessed/x_scaled_binary.csv\").values\n",
    "# y = pd.read_csv(\"/kaggle/input/ton-iot-preprocessed/y_type.csv\")[\"type\"].values    # Multi-Class Classification\n",
    "\n",
    "print(\"All CSVs loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T14:15:32.755775Z",
     "iopub.status.busy": "2025-04-22T14:15:32.755550Z",
     "iopub.status.idle": "2025-04-22T14:15:32.760639Z",
     "shell.execute_reply": "2025-04-22T14:15:32.759903Z",
     "shell.execute_reply.started": "2025-04-22T14:15:32.755757Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [[ 1.14261583e+00 -1.02838123e-01 -5.15379487e-01 ... -4.83640141e-01\n",
      "  -2.27361771e-02 -1.56979794e-01]\n",
      " [ 1.46839879e+00  1.67130963e+00  2.66593705e-01 ... -4.83640141e-01\n",
      "  -2.27361771e-02 -1.56979794e-01]\n",
      " [-1.39334648e-02  7.73964915e-02  1.06775791e+00 ... -4.83640141e-01\n",
      "  -2.27361771e-02 -1.56979794e-01]\n",
      " ...\n",
      " [-7.19142831e-01 -1.18540966e-01  1.31796005e+00 ... -4.83640141e-01\n",
      "  -2.27361771e-02 -1.56979794e-01]\n",
      " [ 4.09292350e-01  1.03229179e+00 -7.69347662e-01 ... -4.83640141e-01\n",
      "  -2.27361771e-02 -1.56979794e-01]\n",
      " [ 1.97732721e-03 -3.14086524e-01 -6.04889073e-01 ...  2.06765302e+00\n",
      "  -2.27361771e-02 -1.56979794e-01]]\n",
      "Target: [0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Features: {x_scaled}\")\n",
    "print(f\"Target: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Phase 4: Preparation for Data Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T14:15:32.761498Z",
     "iopub.status.busy": "2025-04-22T14:15:32.761266Z",
     "iopub.status.idle": "2025-04-22T14:15:33.302947Z",
     "shell.execute_reply": "2025-04-22T14:15:33.302263Z",
     "shell.execute_reply.started": "2025-04-22T14:15:32.761477Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (42000, 42), Validation set: (9000, 42), Test set: (9000, 42)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into training (70%), validation (15%), and testing (15%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(x_scaled, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, Validation set: {X_val.shape}, Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T14:15:33.303961Z",
     "iopub.status.busy": "2025-04-22T14:15:33.303685Z",
     "iopub.status.idle": "2025-04-22T14:15:33.308356Z",
     "shell.execute_reply": "2025-04-22T14:15:33.307690Z",
     "shell.execute_reply.started": "2025-04-22T14:15:33.303937Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_sequences(data, sequence_length, step=1):\n",
    "    \"\"\"\n",
    "    Create sequences for time series analysis from non-sequential data by sliding window approach\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    n_samples = data.shape[0]\n",
    "    # Create sequences by grouping adjacent samples\n",
    "    for i in range(0, n_samples - sequence_length + 1, step):\n",
    "        # Extract sequence of length sequence_length starting at position i\n",
    "        sequence = data[i:i + sequence_length]\n",
    "        sequences.append(sequence)\n",
    "    \n",
    "    return np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T14:15:33.311638Z",
     "iopub.status.busy": "2025-04-22T14:15:33.310858Z",
     "iopub.status.idle": "2025-04-22T14:15:33.903171Z",
     "shell.execute_reply": "2025-04-22T14:15:33.902364Z",
     "shell.execute_reply.started": "2025-04-22T14:15:33.311614Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing sequences for TSMixer...\n",
      "Sequence shapes - Train: (13990, 32, 42), Val: (2990, 32, 42), Test: (2990, 32, 42)\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 32  # Length of input sequence\n",
    "step = 3               # Step size for sliding window\n",
    "\n",
    "# Prepare sequences for training\n",
    "print(\"Preparing sequences for TSMixer...\")\n",
    "X_train_seq = prepare_sequences(X_train, sequence_length, step)\n",
    "y_train_seq = y_train[sequence_length-1::step]  # Use the label at the end of each sequence\n",
    "\n",
    "X_val_seq = prepare_sequences(X_val, sequence_length, step)\n",
    "y_val_seq = y_val[sequence_length-1::step]\n",
    "\n",
    "X_test_seq = prepare_sequences(X_test, sequence_length, step)\n",
    "y_test_seq = y_test[sequence_length-1::step]\n",
    "print(f\"Sequence shapes - Train: {X_train_seq.shape}, Val: {X_val_seq.shape}, Test: {X_test_seq.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T14:15:33.904131Z",
     "iopub.status.busy": "2025-04-22T14:15:33.903931Z",
     "iopub.status.idle": "2025-04-22T14:15:34.838885Z",
     "shell.execute_reply": "2025-04-22T14:15:34.838091Z",
     "shell.execute_reply.started": "2025-04-22T14:15:33.904115Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train_seq, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train_seq, dtype=torch.long).to(device)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val_seq, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val_seq, dtype=torch.long).to(device)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_seq, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test_seq, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Phase 5: Model Definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T14:15:34.840124Z",
     "iopub.status.busy": "2025-04-22T14:15:34.839886Z",
     "iopub.status.idle": "2025-04-22T14:15:34.862323Z",
     "shell.execute_reply": "2025-04-22T14:15:34.861773Z",
     "shell.execute_reply.started": "2025-04-22T14:15:34.840107Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Enhanced TSMixer Model with Attention\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    \"\"\"Channel attention module for focusing on important features\"\"\"\n",
    "    def __init__(self, feat_dim, reduction=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(feat_dim, feat_dim // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(feat_dim // reduction, feat_dim, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, feat_dim)\n",
    "        x_transposed = x.transpose(1, 2)  # (batch_size, feat_dim, seq_len)\n",
    "        \n",
    "        avg_out = self.fc(self.avg_pool(x_transposed).squeeze(-1))\n",
    "        max_out = self.fc(self.max_pool(x_transposed).squeeze(-1))\n",
    "        \n",
    "        out = self.sigmoid(avg_out + max_out).unsqueeze(2)  # (batch_size, feat_dim, 1)\n",
    "        return (x_transposed * out).transpose(1, 2)  # Back to (batch_size, seq_len, feat_dim)\n",
    "\n",
    "\n",
    "class TemporalAttention(nn.Module):\n",
    "    \"\"\"Temporal attention module for focusing on important time steps\"\"\"\n",
    "    def __init__(self, seq_len, reduction=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(seq_len, seq_len // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(seq_len // reduction, seq_len, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, feat_dim)\n",
    "        b, s, f = x.size()\n",
    "        \n",
    "        avg_out = self.fc(self.avg_pool(x).squeeze(-1))\n",
    "        max_out = self.fc(self.max_pool(x).squeeze(-1))\n",
    "        \n",
    "        out = self.sigmoid(avg_out + max_out).unsqueeze(2)  # (batch_size, seq_len, 1)\n",
    "        return x * out\n",
    "\n",
    "\n",
    "class MixerBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the mixer block for TSMixer\n",
    "    \"\"\"\n",
    "    def __init__(self, seq_len, feat_dim, dropout=0.1, \n",
    "                 use_channel_attention=False, use_temporal_attention=False, attention_reduction=16):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Temporal mixing (across sequence dimension)\n",
    "        self.temporal_mlp = nn.Sequential(\n",
    "            nn.Linear(seq_len, seq_len),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(seq_len, seq_len),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # Feature mixing (across feature dimension)\n",
    "        self.feature_mlp = nn.Sequential(\n",
    "            nn.Linear(feat_dim, feat_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(feat_dim, feat_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # Attention mechanisms\n",
    "        self.use_channel_attention = use_channel_attention\n",
    "        self.use_temporal_attention = use_temporal_attention\n",
    "        \n",
    "        if use_channel_attention:\n",
    "            self.channel_attention = ChannelAttention(feat_dim, reduction=attention_reduction)\n",
    "        \n",
    "        if use_temporal_attention:\n",
    "            self.temporal_attention = TemporalAttention(seq_len, reduction=attention_reduction)\n",
    "        \n",
    "        # Layer normalizations\n",
    "        self.norm1 = nn.LayerNorm(feat_dim)\n",
    "        self.norm2 = nn.LayerNorm(feat_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, feat_dim)\n",
    "        \n",
    "        # Temporal mixing (transpose for sequence-wise operations)\n",
    "        residual = x\n",
    "        x = self.norm1(x)\n",
    "        x_transposed = x.transpose(1, 2)  # (batch_size, feat_dim, seq_len)\n",
    "        x_temporal = self.temporal_mlp(x_transposed).transpose(1, 2)  # Back to (batch_size, seq_len, feat_dim)\n",
    "        \n",
    "        # Apply temporal attention if enabled\n",
    "        if self.use_temporal_attention:\n",
    "            x_temporal = self.temporal_attention(x_temporal)\n",
    "            \n",
    "        x = x_temporal + residual\n",
    "        \n",
    "        # Feature mixing\n",
    "        residual = x\n",
    "        x = self.norm2(x)\n",
    "        x_feature = self.feature_mlp(x)\n",
    "        \n",
    "        # Apply channel attention if enabled\n",
    "        if self.use_channel_attention:\n",
    "            x_feature = self.channel_attention(x_feature)\n",
    "            \n",
    "        x = x_feature + residual\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class TSMixer(nn.Module):\n",
    "    \"\"\"\n",
    "    TSMixer model for time series forecasting/classification\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        seq_len, \n",
    "        feat_dim, \n",
    "        num_classes, \n",
    "        hidden_dim=128,\n",
    "        num_blocks=4, \n",
    "        dropout=0.2,\n",
    "        use_channel_attention=False,\n",
    "        use_temporal_attention=False,\n",
    "        attention_reduction=16,\n",
    "        classifier_type='lightweight'  # Options: 'standard', 'lightweight', 'linear', 'enhanced'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "        self.feat_dim = feat_dim\n",
    "        \n",
    "        # Input projection\n",
    "        self.input_projection = nn.Linear(feat_dim, hidden_dim)\n",
    "        \n",
    "        # Stack of Mixer blocks\n",
    "        self.mixer_blocks = nn.ModuleList([\n",
    "            MixerBlock(seq_len, hidden_dim, dropout, \n",
    "                      use_channel_attention, use_temporal_attention, attention_reduction) \n",
    "            for _ in range(num_blocks)\n",
    "        ])\n",
    "        \n",
    "        # Global average pooling\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        # Classification head based on type\n",
    "        if classifier_type == 'standard':\n",
    "            self.classifier = self._standard_classifier(hidden_dim, num_classes, dropout)\n",
    "        elif classifier_type == 'lightweight':\n",
    "            self.classifier = self._lightweight_classifier(hidden_dim, num_classes, dropout)\n",
    "        elif classifier_type == 'linear':\n",
    "            self.classifier = self._linear_classifier(hidden_dim, num_classes)\n",
    "        elif classifier_type == 'enhanced':\n",
    "            self.classifier = self._enhanced_classifier(hidden_dim, num_classes, dropout)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown classifier type: {classifier_type}\")\n",
    "    \n",
    "    def _standard_classifier(self, feat_dim, num_classes, dropout=0.2):\n",
    "        \"\"\"Standard classification head with two hidden layers\"\"\"\n",
    "        hidden_dim = feat_dim * 2\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(feat_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def _lightweight_classifier(self, feat_dim, num_classes, dropout=0.3):\n",
    "        \"\"\"Lightweight classification head with a single hidden layer\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(feat_dim, feat_dim // 2),\n",
    "            nn.BatchNorm1d(feat_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(feat_dim // 2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def _linear_classifier(self, feat_dim, num_classes):\n",
    "        \"\"\"Simple linear classification head\"\"\"\n",
    "        return nn.Linear(feat_dim, num_classes)\n",
    "    \n",
    "    def _enhanced_classifier(self, feat_dim, num_classes, dropout=0.3):\n",
    "        \"\"\"Enhanced classification head with residual connections\"\"\"\n",
    "        return EnhancedClassifier(feat_dim, num_classes, dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, feat_dim)\n",
    "        \n",
    "        # Input projection\n",
    "        x = self.input_projection(x)  # (batch_size, seq_len, hidden_dim)\n",
    "        \n",
    "        # Apply mixer blocks\n",
    "        for mixer_block in self.mixer_blocks:\n",
    "            x = mixer_block(x)\n",
    "        \n",
    "        # Global pooling (convert to channel-first for pooling)\n",
    "        x = x.transpose(1, 2)  # (batch_size, hidden_dim, seq_len)\n",
    "        x = self.pool(x).squeeze(-1)  # (batch_size, hidden_dim)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(x)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "class EnhancedClassifier(nn.Module):\n",
    "    \"\"\"Enhanced classification head with residual connections\"\"\"\n",
    "    def __init__(self, feat_dim, num_classes, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(feat_dim, feat_dim),\n",
    "            nn.LayerNorm(feat_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(feat_dim, feat_dim // 2),\n",
    "            nn.LayerNorm(feat_dim // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Linear(feat_dim // 2, num_classes)\n",
    "        \n",
    "        # Residual connection\n",
    "        self.shortcut = nn.Linear(feat_dim, feat_dim // 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # First block\n",
    "        out1 = self.layer1(x)\n",
    "        out1 = out1 + x  # Residual connection\n",
    "        \n",
    "        # Second block with shortcut\n",
    "        out2 = self.layer2(out1)\n",
    "        shortcut = self.shortcut(x)\n",
    "        out2 = out2 + shortcut  # Residual connection\n",
    "        \n",
    "        # Final classification layer\n",
    "        return self.layer3(out2)\n",
    "\n",
    "\n",
    "# Example usage function\n",
    "def create_tsmixer_model(\n",
    "    seq_len, \n",
    "    feat_dim, \n",
    "    num_classes, \n",
    "    hidden_dim=256,\n",
    "    num_blocks=4, \n",
    "    dropout=0.2,\n",
    "    use_channel_attention=False,\n",
    "    use_temporal_attention=False,\n",
    "    attention_reduction=16,\n",
    "    classifier_type='lightweight'  # Options: 'standard', 'lightweight', 'linear', 'enhanced'\n",
    "):\n",
    "    \"\"\"Helper function to create a TSMixer model with specified parameters\"\"\"\n",
    "    return TSMixer(\n",
    "        seq_len=seq_len,\n",
    "        feat_dim=feat_dim,\n",
    "        num_classes=num_classes,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_blocks=num_blocks,\n",
    "        dropout=dropout,\n",
    "        use_channel_attention=use_channel_attention,\n",
    "        use_temporal_attention=use_temporal_attention,\n",
    "        attention_reduction=attention_reduction,\n",
    "        classifier_type=classifier_type\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T14:15:34.863388Z",
     "iopub.status.busy": "2025-04-22T14:15:34.863103Z",
     "iopub.status.idle": "2025-04-22T14:15:34.882574Z",
     "shell.execute_reply": "2025-04-22T14:15:34.881917Z",
     "shell.execute_reply.started": "2025-04-22T14:15:34.863366Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Focal Loss for handling class imbalance\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.ce = nn.CrossEntropyLoss(reduction='none')\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        logp = self.ce(inputs, targets)\n",
    "        p = torch.exp(-logp)\n",
    "        loss = self.alpha * (1 - p) ** self.gamma * logp\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T14:15:34.883791Z",
     "iopub.status.busy": "2025-04-22T14:15:34.883579Z",
     "iopub.status.idle": "2025-04-22T14:15:34.904084Z",
     "shell.execute_reply": "2025-04-22T14:15:34.903520Z",
     "shell.execute_reply.started": "2025-04-22T14:15:34.883776Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler=None, \n",
    "                num_epochs=30, patience=5, clip_value=None):\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    no_improve_epochs = 0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    best_model_state = None\n",
    "\n",
    "    total_start_time = time.time()  # Start measuring total training time\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            if clip_value is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "                \n",
    "            optimizer.step()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_acc = train_correct / train_total\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        if scheduler:\n",
    "            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch {epoch}/{num_epochs} [{epoch_time:.1f}s] - \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} - \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            no_improve_epochs = 0\n",
    "            print(f\"New best validation accuracy: {best_val_acc:.4f}\")\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "            \n",
    "        if no_improve_epochs >= patience:\n",
    "            print(f\"Early stopping triggered after epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "    total_training_time = time.time() - total_start_time\n",
    "    print(f\"⏱️ Total training time: {total_training_time:.2f} seconds\")\n",
    "\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(f\"Restored best model with validation accuracy: {best_val_acc:.4f}\")\n",
    "    \n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T14:15:34.905271Z",
     "iopub.status.busy": "2025-04-22T14:15:34.905054Z",
     "iopub.status.idle": "2025-04-22T14:15:34.923719Z",
     "shell.execute_reply": "2025-04-22T14:15:34.923163Z",
     "shell.execute_reply.started": "2025-04-22T14:15:34.905247Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "\n",
    "def evaluate_model(model, test_loader, label_mapping, save_path='model_evaluation'):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_outputs = []  # Store raw outputs for SHAP analysis\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_outputs.append(outputs.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_outputs = np.concatenate(all_outputs, axis=0)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    print(\"\\nModel Evaluation Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\\n\")\n",
    "    \n",
    "    # Display per-class metrics\n",
    "    per_class_accuracy = {}\n",
    "    for cls in np.unique(all_labels):\n",
    "        cls_indices = (all_labels == cls)\n",
    "        if np.sum(cls_indices) > 0:  # Avoid division by zero\n",
    "            cls_acc = accuracy_score(all_labels[cls_indices], all_preds[cls_indices])\n",
    "            per_class_accuracy[cls] = cls_acc\n",
    "    \n",
    "    print(\"Per-class accuracy:\")\n",
    "    for cls, acc in per_class_accuracy.items():\n",
    "        cls_name = next(k for k, v in label_mapping.items() if v == cls)\n",
    "        print(f\"Class {cls} ({cls_name}): {acc:.4f}\")\n",
    "    \n",
    "    # Display classification report\n",
    "    target_names = [f\"{k} ({v})\" for k, v in label_mapping.items()]\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=target_names))\n",
    "    \n",
    "    # Plot confusion matrix with percentages\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    \n",
    "    sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=target_names,\n",
    "                yticklabels=target_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix (Percentage %)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_path}_confusion_matrix_percentage.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot raw counts confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=target_names,\n",
    "                yticklabels=target_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix (Raw Counts)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_path}_confusion_matrix_raw.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    return accuracy, precision, recall, f1, per_class_accuracy, all_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T14:15:34.925005Z",
     "iopub.status.busy": "2025-04-22T14:15:34.924372Z",
     "iopub.status.idle": "2025-04-22T14:15:34.942016Z",
     "shell.execute_reply": "2025-04-22T14:15:34.941420Z",
     "shell.execute_reply.started": "2025-04-22T14:15:34.924981Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_data_loaders(batch_size):\n",
    "    \"\"\"Create DataLoaders with the given batch size\"\"\"\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T14:15:34.942823Z",
     "iopub.status.busy": "2025-04-22T14:15:34.942664Z",
     "iopub.status.idle": "2025-04-22T15:02:08.821568Z",
     "shell.execute_reply": "2025-04-22T15:02:08.820755Z",
     "shell.execute_reply.started": "2025-04-22T14:15:34.942810Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 [10.4s] - Train Loss: 0.1468, Train Acc: 0.9434 - Val Loss: 0.0765, Val Acc: 0.9726\n",
      "New best validation accuracy: 0.9726\n",
      "Epoch 2/30 [9.8s] - Train Loss: 0.0726, Train Acc: 0.9756 - Val Loss: 0.0714, Val Acc: 0.9756\n",
      "New best validation accuracy: 0.9756\n",
      "Epoch 3/30 [10.0s] - Train Loss: 0.0644, Train Acc: 0.9781 - Val Loss: 0.0655, Val Acc: 0.9786\n",
      "New best validation accuracy: 0.9786\n",
      "Epoch 4/30 [10.7s] - Train Loss: 0.0603, Train Acc: 0.9800 - Val Loss: 0.0605, Val Acc: 0.9829\n",
      "New best validation accuracy: 0.9829\n",
      "Epoch 5/30 [10.9s] - Train Loss: 0.0536, Train Acc: 0.9824 - Val Loss: 0.0555, Val Acc: 0.9839\n",
      "New best validation accuracy: 0.9839\n",
      "Epoch 6/30 [10.0s] - Train Loss: 0.0519, Train Acc: 0.9818 - Val Loss: 0.0607, Val Acc: 0.9833\n",
      "Epoch 7/30 [10.1s] - Train Loss: 0.0476, Train Acc: 0.9854 - Val Loss: 0.0688, Val Acc: 0.9816\n",
      "Epoch 8/30 [9.8s] - Train Loss: 0.0476, Train Acc: 0.9847 - Val Loss: 0.0564, Val Acc: 0.9799\n",
      "Epoch 9/30 [9.8s] - Train Loss: 0.0368, Train Acc: 0.9867 - Val Loss: 0.0595, Val Acc: 0.9836\n",
      "Epoch 10/30 [9.9s] - Train Loss: 0.0324, Train Acc: 0.9887 - Val Loss: 0.0647, Val Acc: 0.9843\n",
      "New best validation accuracy: 0.9843\n",
      "Epoch 11/30 [9.8s] - Train Loss: 0.0306, Train Acc: 0.9891 - Val Loss: 0.0628, Val Acc: 0.9836\n",
      "Epoch 12/30 [9.7s] - Train Loss: 0.0242, Train Acc: 0.9904 - Val Loss: 0.0681, Val Acc: 0.9839\n",
      "Epoch 13/30 [9.8s] - Train Loss: 0.0212, Train Acc: 0.9917 - Val Loss: 0.0742, Val Acc: 0.9843\n",
      "Epoch 14/30 [10.0s] - Train Loss: 0.0200, Train Acc: 0.9915 - Val Loss: 0.0749, Val Acc: 0.9836\n",
      "Epoch 15/30 [9.7s] - Train Loss: 0.0143, Train Acc: 0.9942 - Val Loss: 0.0855, Val Acc: 0.9836\n",
      "Early stopping triggered after epoch 15\n",
      "⏱️ Total training time: 150.37 seconds\n",
      "Restored best model with validation accuracy: 0.9843\n",
      "Base TSMixer validation accuracy: 0.9843\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Train with default parameters\n",
    "# Create dataloaders with default batch size\n",
    "batch_size = 32\n",
    "train_loader, val_loader, test_loader = create_data_loaders(batch_size)\n",
    "\n",
    "# Define and train TSMixer with default parameters\n",
    "default_model = TSMixer(\n",
    "    seq_len=X_train_seq.shape[1],          \n",
    "    feat_dim=X_train_seq.shape[2],         \n",
    "    num_classes=len(np.unique(y_train_seq)), \n",
    "    hidden_dim=64,\n",
    "    num_blocks=15,\n",
    "    dropout=0.1,\n",
    "    use_channel_attention=False,\n",
    "    use_temporal_attention=False,\n",
    "    attention_reduction=16\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(default_model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "# Call train_model with parameters in the correct order\n",
    "default_model, base_history = train_model(\n",
    "    model=default_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=30,\n",
    "    patience=5\n",
    ")\n",
    "\n",
    "# Evaluate base model\n",
    "def calculate_accuracy(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return correct / total\n",
    "\n",
    "# Then use this instead of the second evaluate_model function\n",
    "base_val_acc = calculate_accuracy(default_model, val_loader)\n",
    "print(f\"Base TSMixer validation accuracy: {base_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T15:02:08.822975Z",
     "iopub.status.busy": "2025-04-22T15:02:08.822512Z",
     "iopub.status.idle": "2025-04-22T15:02:14.720179Z",
     "shell.execute_reply": "2025-04-22T15:02:14.719449Z",
     "shell.execute_reply.started": "2025-04-22T15:02:08.822957Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Base Model Evaluation ---\n",
      "\n",
      "Model Evaluation Results:\n",
      "Accuracy: 0.9833\n",
      "Precision: 0.9833\n",
      "Recall: 0.9833\n",
      "F1 Score: 0.9833\n",
      "\n",
      "Per-class accuracy:\n",
      "Class 0 (Normal): 0.9859\n",
      "Class 1 (Attack): 0.9806\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Normal (0)       0.98      0.99      0.98      1494\n",
      "  Attack (1)       0.99      0.98      0.98      1496\n",
      "\n",
      "    accuracy                           0.98      2990\n",
      "   macro avg       0.98      0.98      0.98      2990\n",
      "weighted avg       0.98      0.98      0.98      2990\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n--- Base Model Evaluation ---\")\n",
    "accuracy, precision, recall, f1, per_class_accuracy, all_outputs = evaluate_model(\n",
    "    default_model,\n",
    "    test_loader,\n",
    "    label_mapping = {'Normal': 0, 'Attack': 1},                            # Binary Classification\n",
    "    # label_mapping = {'dos': 0, 'normal': 1, 'password': 2, 'scanning': 3}, # Multi-Class Classification\n",
    "    save_path='default_model'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Phase 6: Hyperparameter Tuning with Optuna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T15:02:14.721343Z",
     "iopub.status.busy": "2025-04-22T15:02:14.721073Z",
     "iopub.status.idle": "2025-04-22T15:02:14.732841Z",
     "shell.execute_reply": "2025-04-22T15:02:14.732049Z",
     "shell.execute_reply.started": "2025-04-22T15:02:14.721319Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Optuna objective function for hyperparameter tuning\"\"\"\n",
    "    # Get sequence length from data\n",
    "    sequence_length = X_train_seq.shape[1]\n",
    "\n",
    "    # Hyperparameters to tune\n",
    "    batch_size = trial.suggest_int('batch_size', 32, 96, step=8) #32\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 256, 640, step=32) #64\n",
    "    num_blocks = trial.suggest_int('num_blocks', 15, 30)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.05, 0.5, log=True) # 0.1-0.5, step=0.01\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-7, 1e-3, log=True)\n",
    "    focal_alpha = trial.suggest_float('focal_alpha', 0.25, 3.5, step=0.25) #0.25\n",
    "    focal_gamma = trial.suggest_float('focal_gamma', 0.25, 3.5, step=0.25) #0.5\n",
    "    use_channel_attention = trial.suggest_categorical('use_channel_attention', [True, False])\n",
    "    use_temporal_attention = trial.suggest_categorical('use_temporal_attention', [True, False])\n",
    "    \n",
    "    if use_channel_attention or use_temporal_attention:\n",
    "        attention_reduction = trial.suggest_int('attention_reduction', 8, 70, step=8)\n",
    "    else:\n",
    "        attention_reduction = 16  # Default value, won't be used\n",
    "    \n",
    "    # Create model\n",
    "    num_classes = len(np.unique(y_train_seq))\n",
    "    feature_dim = X_train_seq.shape[2]\n",
    "    \n",
    "    model = TSMixer(\n",
    "        seq_len=sequence_length,  # Use seq_len to match the parameter name in TSMixer\n",
    "        feat_dim=feature_dim,\n",
    "        num_classes=num_classes,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_blocks=num_blocks,\n",
    "        dropout=dropout_rate,\n",
    "        use_channel_attention=use_channel_attention,\n",
    "        use_temporal_attention=use_temporal_attention,\n",
    "        attention_reduction=attention_reduction\n",
    "\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = FocalLoss(alpha=focal_alpha, gamma=focal_gamma, reduction='mean')\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    # Scheduler\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=False)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader, val_loader, _ = create_data_loaders(batch_size)\n",
    "    \n",
    "    # Train for a few epochs to evaluate performance\n",
    "    num_epochs = 20\n",
    "    patience = 7\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "    \n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "            \n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "                \n",
    "            optimizer.step()\n",
    "                \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                    \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "            \n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_accuracy = correct_val / total_val\n",
    "            \n",
    "        # Update scheduler\n",
    "        scheduler.step(val_loss)\n",
    "            \n",
    "        # Early stopping based on validation accuracy\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= patience:\n",
    "            break\n",
    "    \n",
    "    return best_val_acc  # Fixed indentation here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T15:02:14.733893Z",
     "iopub.status.busy": "2025-04-22T15:02:14.733563Z",
     "iopub.status.idle": "2025-04-22T17:17:45.768847Z",
     "shell.execute_reply": "2025-04-22T17:17:45.768106Z",
     "shell.execute_reply.started": "2025-04-22T15:02:14.733857Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 06:21:30,745] A new study created in memory with name: no-name-bd25657b-0479-4066-87ab-e98c57c97c72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter optimization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-27 06:26:41,684] Trial 0 finished with value: 0.9859531772575251 and parameters: {'batch_size': 56, 'hidden_dim': 640, 'num_blocks': 26, 'dropout_rate': 0.19843966652221853, 'learning_rate': 0.00029380279387035364, 'weight_decay': 4.207053950287931e-07, 'focal_alpha': 0.25, 'focal_gamma': 3.25, 'use_channel_attention': False, 'use_temporal_attention': False}. Best is trial 0 with value: 0.9859531772575251.\n",
      "[I 2025-04-27 06:29:00,916] Trial 1 finished with value: 0.9866220735785953 and parameters: {'batch_size': 88, 'hidden_dim': 320, 'num_blocks': 17, 'dropout_rate': 0.07627364729026305, 'learning_rate': 0.0008179499475211679, 'weight_decay': 1.2561043700013547e-05, 'focal_alpha': 1.75, 'focal_gamma': 1.25, 'use_channel_attention': True, 'use_temporal_attention': False, 'attention_reduction': 32}. Best is trial 1 with value: 0.9866220735785953.\n",
      "[I 2025-04-27 06:32:17,445] Trial 2 finished with value: 0.9852842809364548 and parameters: {'batch_size': 88, 'hidden_dim': 320, 'num_blocks': 23, 'dropout_rate': 0.19560708142748476, 'learning_rate': 0.000137832374550072, 'weight_decay': 2.692646910086177e-05, 'focal_alpha': 0.75, 'focal_gamma': 0.25, 'use_channel_attention': False, 'use_temporal_attention': True, 'attention_reduction': 8}. Best is trial 1 with value: 0.9866220735785953.\n",
      "[I 2025-04-27 06:35:12,398] Trial 3 finished with value: 0.98561872909699 and parameters: {'batch_size': 80, 'hidden_dim': 416, 'num_blocks': 16, 'dropout_rate': 0.15636765183901852, 'learning_rate': 0.00012681352169084607, 'weight_decay': 0.0004337920697490938, 'focal_alpha': 1.0, 'focal_gamma': 2.5, 'use_channel_attention': False, 'use_temporal_attention': True, 'attention_reduction': 64}. Best is trial 1 with value: 0.9866220735785953.\n",
      "[I 2025-04-27 06:38:07,654] Trial 4 finished with value: 0.5123745819397993 and parameters: {'batch_size': 80, 'hidden_dim': 640, 'num_blocks': 29, 'dropout_rate': 0.19809338952032915, 'learning_rate': 0.058293845429947415, 'weight_decay': 2.2592797420156943e-07, 'focal_alpha': 0.75, 'focal_gamma': 0.25, 'use_channel_attention': False, 'use_temporal_attention': False}. Best is trial 1 with value: 0.9866220735785953.\n",
      "[I 2025-04-27 06:43:52,466] Trial 5 finished with value: 0.9866220735785953 and parameters: {'batch_size': 56, 'hidden_dim': 352, 'num_blocks': 23, 'dropout_rate': 0.06916624987609979, 'learning_rate': 0.025502980701628937, 'weight_decay': 1.9870215385428617e-07, 'focal_alpha': 3.5, 'focal_gamma': 2.75, 'use_channel_attention': True, 'use_temporal_attention': True, 'attention_reduction': 48}. Best is trial 1 with value: 0.9866220735785953.\n",
      "[I 2025-04-27 06:46:37,712] Trial 6 finished with value: 0.98561872909699 and parameters: {'batch_size': 80, 'hidden_dim': 256, 'num_blocks': 20, 'dropout_rate': 0.06528885674498615, 'learning_rate': 0.038842777547031436, 'weight_decay': 3.1130959561221214e-05, 'focal_alpha': 1.25, 'focal_gamma': 0.25, 'use_channel_attention': False, 'use_temporal_attention': True, 'attention_reduction': 64}. Best is trial 1 with value: 0.9866220735785953.\n",
      "[I 2025-04-27 07:02:31,173] Trial 8 finished with value: 0.98561872909699 and parameters: {'batch_size': 48, 'hidden_dim': 448, 'num_blocks': 29, 'dropout_rate': 0.08876918518261123, 'learning_rate': 0.001702741688676441, 'weight_decay': 0.00010524574681335637, 'focal_alpha': 1.0, 'focal_gamma': 0.5, 'use_channel_attention': True, 'use_temporal_attention': True, 'attention_reduction': 48}. Best is trial 7 with value: 0.9876254180602007.\n",
      "[I 2025-04-27 07:05:40,325] Trial 9 finished with value: 0.9859531772575251 and parameters: {'batch_size': 88, 'hidden_dim': 576, 'num_blocks': 17, 'dropout_rate': 0.3904172542771205, 'learning_rate': 0.0041497957898915935, 'weight_decay': 0.0001697307853246701, 'focal_alpha': 3.25, 'focal_gamma': 1.25, 'use_channel_attention': False, 'use_temporal_attention': False}. Best is trial 7 with value: 0.9876254180602007.\n",
      "[I 2025-04-27 07:19:39,926] Trial 10 finished with value: 0.9862876254180603 and parameters: {'batch_size': 32, 'hidden_dim': 512, 'num_blocks': 26, 'dropout_rate': 0.4376905152029976, 'learning_rate': 0.008322724281704738, 'weight_decay': 2.373942395529251e-06, 'focal_alpha': 2.5, 'focal_gamma': 2.0, 'use_channel_attention': True, 'use_temporal_attention': True, 'attention_reduction': 24}. Best is trial 7 with value: 0.9876254180602007.\n",
      "[I 2025-04-27 07:22:34,346] Trial 11 finished with value: 0.9842809364548495 and parameters: {'batch_size': 64, 'hidden_dim': 256, 'num_blocks': 19, 'dropout_rate': 0.11330466982937909, 'learning_rate': 0.0009012779589354669, 'weight_decay': 5.1103332581513954e-06, 'focal_alpha': 2.0, 'focal_gamma': 1.25, 'use_channel_attention': True, 'use_temporal_attention': False, 'attention_reduction': 32}. Best is trial 7 with value: 0.9876254180602007.\n",
      "[W 2025-04-27 07:23:32,082] Trial 12 failed with parameters: {'batch_size': 96, 'hidden_dim': 352, 'num_blocks': 26, 'dropout_rate': 0.30399558463116705, 'learning_rate': 0.0007370120807226626, 'weight_decay': 0.0009639757903159521, 'focal_alpha': 2.0, 'focal_gamma': 1.5, 'use_channel_attention': True, 'use_temporal_attention': False, 'attention_reduction': 40} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_31/3441177406.py\", line 72, in objective\n",
      "    loss.backward()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 581, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 825, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-04-27 07:23:32,091] Trial 12 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/1921379789.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpruner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMedianPruner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_startup_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_warmup_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7200\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 2 hours max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     ):\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31/3441177406.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting hyperparameter optimization...\")\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=TPESampler(seed=42),\n",
    "    pruner=MedianPruner(n_startup_trials=5, n_warmup_steps=5)\n",
    ")\n",
    "study.optimize(objective, n_trials=15, timeout=7200)  # 2 hours max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:17:45.769997Z",
     "iopub.status.busy": "2025-04-22T17:17:45.769732Z",
     "iopub.status.idle": "2025-04-22T17:17:45.774868Z",
     "shell.execute_reply": "2025-04-22T17:17:45.774114Z",
     "shell.execute_reply.started": "2025-04-22T17:17:45.769974Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Print optimization results\n",
    "\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "best_params = study.best_params\n",
    "pp.pprint(best_params)\n",
    "print(f\"Best validation accuracy: {study.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:17:45.775820Z",
     "iopub.status.busy": "2025-04-22T17:17:45.775594Z",
     "iopub.status.idle": "2025-04-22T17:17:46.421012Z",
     "shell.execute_reply": "2025-04-22T17:17:46.420298Z",
     "shell.execute_reply.started": "2025-04-22T17:17:45.775805Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot optimization history\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "optuna.visualization.matplotlib.plot_optimization_history(study)\n",
    "plt.title('Optimization History')\n",
    "plt.tight_layout()\n",
    "plt.savefig('optimization_history.png')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:17:46.422022Z",
     "iopub.status.busy": "2025-04-22T17:17:46.421787Z",
     "iopub.status.idle": "2025-04-22T17:17:46.957192Z",
     "shell.execute_reply": "2025-04-22T17:17:46.956421Z",
     "shell.execute_reply.started": "2025-04-22T17:17:46.421998Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot parameter importances\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "optuna.visualization.matplotlib.plot_param_importances(study)\n",
    "plt.title('Parameter Importances')\n",
    "plt.tight_layout()\n",
    "plt.savefig('parameter_importances.png')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Phase 7: Train the best model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:17:46.958827Z",
     "iopub.status.busy": "2025-04-22T17:17:46.958210Z",
     "iopub.status.idle": "2025-04-22T17:17:47.029821Z",
     "shell.execute_reply": "2025-04-22T17:17:47.029093Z",
     "shell.execute_reply.started": "2025-04-22T17:17:46.958807Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "print(\"\\nTraining final model with best hyperparameters...\")\n",
    "\n",
    "# Create dataloaders with best batch size\n",
    "train_loader, val_loader, test_loader = create_data_loaders(best_params['batch_size'])\n",
    "\n",
    "# Create model with best hyperparameters\n",
    "num_classes = len(np.unique(y_train_seq))\n",
    "feature_dim = X_train_seq.shape[2]\n",
    "\n",
    "sequence_length = X_train_seq.shape[1]\n",
    "\n",
    "best_model = TSMixer(\n",
    "    seq_len=sequence_length,  # Use seq_len to match parameter in TSMixer\n",
    "    feat_dim=feature_dim,\n",
    "    num_classes=num_classes,\n",
    "    hidden_dim=best_params['hidden_dim'],\n",
    "    num_blocks=best_params['num_blocks'],\n",
    "    dropout=best_params['dropout_rate'],\n",
    "    use_channel_attention=best_params['use_channel_attention'],\n",
    "    use_temporal_attention=best_params['use_temporal_attention'],\n",
    "    attention_reduction=best_params.get('attention_reduction', 16)\n",
    ")\n",
    "best_model = best_model.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = FocalLoss(\n",
    "    alpha=best_params['focal_alpha'],\n",
    "    gamma=best_params['focal_gamma'],\n",
    "    reduction='mean'\n",
    ")\n",
    "\n",
    "# Adam Optimizer\n",
    "optimizer = optim.Adam(\n",
    "    best_model.parameters(),\n",
    "    lr=best_params['learning_rate'],\n",
    "    weight_decay=best_params['weight_decay']\n",
    ")\n",
    "\n",
    "# Use OneCycleLR for final training\n",
    "num_epochs = 30\n",
    "steps_per_epoch = len(train_loader)\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=best_params['learning_rate'],\n",
    "    epochs=num_epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    pct_start=0.3,\n",
    "    div_factor=10.0,\n",
    "    final_div_factor=100.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:17:47.031012Z",
     "iopub.status.busy": "2025-04-22T17:17:47.030798Z",
     "iopub.status.idle": "2025-04-22T17:48:58.497652Z",
     "shell.execute_reply": "2025-04-22T17:48:58.496936Z",
     "shell.execute_reply.started": "2025-04-22T17:17:47.030996Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "best_model, history = train_model(\n",
    "    best_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    num_epochs=num_epochs,\n",
    "    patience=10,\n",
    "    clip_value=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:48:58.498742Z",
     "iopub.status.busy": "2025-04-22T17:48:58.498502Z",
     "iopub.status.idle": "2025-04-22T17:48:58.542613Z",
     "shell.execute_reply": "2025-04-22T17:48:58.542079Z",
     "shell.execute_reply.started": "2025-04-22T17:48:58.498725Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(best_model.state_dict(), \"tsmixer_best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:48:58.543610Z",
     "iopub.status.busy": "2025-04-22T17:48:58.543354Z",
     "iopub.status.idle": "2025-04-22T17:48:59.313045Z",
     "shell.execute_reply": "2025-04-22T17:48:59.312372Z",
     "shell.execute_reply.started": "2025-04-22T17:48:58.543593Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss During Training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "plt.title('Accuracy During Training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Phase 8: Evaluate the final model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:48:59.316350Z",
     "iopub.status.busy": "2025-04-22T17:48:59.316150Z",
     "iopub.status.idle": "2025-04-22T17:49:04.874371Z",
     "shell.execute_reply": "2025-04-22T17:49:04.873602Z",
     "shell.execute_reply.started": "2025-04-22T17:48:59.316335Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- Final Model Evaluation ---\")\n",
    "accuracy, precision, recall, f1, per_class_accuracy, all_outputs = evaluate_model(\n",
    "    best_model,\n",
    "    test_loader,\n",
    "    label_mapping = {'Normal': 0, 'Attack': 1},                            # Binary Classification\n",
    "    # label_mapping = {'dos': 0, 'normal': 1, 'password': 2, 'scanning': 3}, # Multi-Class Classification\n",
    "    save_path='final_model'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Phase 9: Explainable AI (XAI) Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:49:04.875547Z",
     "iopub.status.busy": "2025-04-22T17:49:04.875253Z",
     "iopub.status.idle": "2025-04-22T17:49:04.923937Z",
     "shell.execute_reply": "2025-04-22T17:49:04.923351Z",
     "shell.execute_reply.started": "2025-04-22T17:49:04.875522Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- Explainability Analysis with SHAP ---\")\n",
    "\n",
    "# Create a wrapper class that properly handles PyTorch model for SHAP\n",
    "class ModelWrapper:\n",
    "    def __init__(self, model, device='cpu'):\n",
    "        self.model = model.to(device)\n",
    "        self.model.eval()\n",
    "        self.device = device\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # Handle different types of input\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x_tensor = torch.tensor(x, dtype=torch.float32).to(self.device)\n",
    "        else:\n",
    "            x_tensor = x.to(self.device)\n",
    "        \n",
    "        # Ensure model is in eval mode\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Clone tensors to avoid in-place modification issues\n",
    "        with torch.no_grad():\n",
    "            output = self.model(x_tensor.clone()).detach().cpu().numpy()\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Select a subset of test data for SHAP analysis\n",
    "num_shap_samples = min(50, len(X_test_seq))  # Reduced sample size for faster computation\n",
    "shap_samples = X_test_seq[:num_shap_samples]\n",
    "\n",
    "# Ensure all operations are on CPU to avoid CUDA issues with SHAP\n",
    "device = 'cpu'\n",
    "best_model = best_model.to(device)\n",
    "\n",
    "# Create background data for SHAP\n",
    "background_size = min(50, len(X_train_seq))  # Use a smaller subset for background\n",
    "background = X_train_seq[:background_size]\n",
    "\n",
    "# Try different SHAP explainer approaches with proper error handling\n",
    "print(\"Attempting SHAP analysis with different explainers...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:49:04.924995Z",
     "iopub.status.busy": "2025-04-22T17:49:04.924730Z",
     "iopub.status.idle": "2025-04-22T17:51:10.950787Z",
     "shell.execute_reply": "2025-04-22T17:51:10.949975Z",
     "shell.execute_reply.started": "2025-04-22T17:49:04.924970Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1. First try: Use GradientExplainer which is often more stable with PyTorch\n",
    "try:\n",
    "    print(\"Trying GradientExplainer...\")\n",
    "    # Prepare data properly for GradientExplainer\n",
    "    background_tensor = torch.tensor(background, dtype=torch.float32).to(device)\n",
    "    shap_tensor = torch.tensor(shap_samples, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Wrap the model\n",
    "    wrapped_model = ModelWrapper(best_model, device)\n",
    "    \n",
    "    # Create a gradient explainer\n",
    "    gradient_explainer = shap.GradientExplainer(\n",
    "        model=best_model,\n",
    "        data=background_tensor\n",
    "    )\n",
    "    \n",
    "    # Calculate SHAP values\n",
    "    shap_values = gradient_explainer.shap_values(shap_tensor)\n",
    "    \n",
    "    # For classification models, shap_values will be a list of arrays (one per class)\n",
    "    if isinstance(shap_values, list):\n",
    "        # For visualization, we'll use the predicted class SHAP values\n",
    "        with torch.no_grad():\n",
    "            predictions = best_model(shap_tensor).argmax(dim=1).cpu().numpy()\n",
    "        \n",
    "        # Create feature importance plot (average across samples)\n",
    "        plt.figure(figsize=(14, 10))\n",
    "        \n",
    "        # Sum absolute SHAP values across classes and features\n",
    "        aggregated_shap = np.zeros((shap_samples.shape[2]))\n",
    "        for class_idx in range(len(shap_values)):\n",
    "            # Sum across samples and sequence length, get average importance per feature\n",
    "            class_shap = np.abs(shap_values[class_idx]).mean(axis=0).mean(axis=0)\n",
    "            aggregated_shap += class_shap\n",
    "            \n",
    "        # Sort features by importance\n",
    "        feature_indices = np.argsort(-aggregated_shap)\n",
    "        feature_names = [f\"Feature {i}\" for i in range(shap_samples.shape[2])]\n",
    "        \n",
    "        # Create bar plot of feature importance\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.barh(\n",
    "            y=np.array(feature_names)[feature_indices[:20]], \n",
    "            width=aggregated_shap[feature_indices[:20]]\n",
    "        )\n",
    "        plt.title('Feature Importance Based on SHAP Values (GradientExplainer)')\n",
    "        plt.xlabel('Mean |SHAP Value|')\n",
    "        plt.gca().invert_yaxis()  # Display highest values at the top\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('shap_gradient_feature_importance.png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"GradientExplainer analysis completed successfully.\")\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected SHAP values format from GradientExplainer.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"GradientExplainer failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:51:10.951869Z",
     "iopub.status.busy": "2025-04-22T17:51:10.951650Z",
     "iopub.status.idle": "2025-04-22T17:51:11.283102Z",
     "shell.execute_reply": "2025-04-22T17:51:11.282037Z",
     "shell.execute_reply.started": "2025-04-22T17:51:10.951853Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Modified approach for DeepExplainer that avoids the view modification error\n",
    "try:\n",
    "    print(\"Trying improved DeepExplainer approach...\")\n",
    "    \n",
    "    # Create a proper wrapper for the model\n",
    "    class SHAPModelWrapper(nn.Module):\n",
    "        def __init__(self, model):\n",
    "            super().__init__()\n",
    "            self.model = model\n",
    "            \n",
    "        def forward(self, x):\n",
    "            # Important: clone the input to avoid in-place modifications\n",
    "            return self.model(x.clone())\n",
    "    \n",
    "    # Wrap the model\n",
    "    wrapped_model = SHAPModelWrapper(best_model)\n",
    "    wrapped_model.eval()\n",
    "    \n",
    "    # Convert background data properly\n",
    "    background_tensor = torch.tensor(background, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Create DeepExplainer with wrapped model\n",
    "    deep_explainer = shap.DeepExplainer(wrapped_model, background_tensor)\n",
    "    \n",
    "    # Get SHAP values for samples (use smaller batch if needed)\n",
    "    sample_tensor = torch.tensor(shap_samples[:10], dtype=torch.float32).to(device)\n",
    "    shap_values = deep_explainer.shap_values(sample_tensor)\n",
    "    \n",
    "    # Continue with visualization as before...\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Improved DeepExplainer failed: {str(e)}\")\n",
    "    \n",
    "    # Alternative: Try KernelExplainer as a fallback\n",
    "    try:\n",
    "        print(\"Falling back to KernelExplainer...\")\n",
    "        \n",
    "        model_wrapper = ModelWrapper(best_model, device)\n",
    "        \n",
    "        # Reshape data for KernelExplainer (flatten sequence dimension)\n",
    "        background_flat = background.reshape(background.shape[0], -1)\n",
    "        samples_flat = shap_samples.reshape(shap_samples.shape[0], -1)\n",
    "        \n",
    "        # Create explainer with smaller subset for speed\n",
    "        kernel_explainer = shap.KernelExplainer(\n",
    "            model_wrapper,\n",
    "            shap.sample(background_flat, min(100, len(background_flat)))\n",
    "        )\n",
    "        \n",
    "        # Calculate SHAP values on smaller subset for speed\n",
    "        kernel_shap_values = kernel_explainer.shap_values(\n",
    "            shap.sample(samples_flat, min(20, len(samples_flat)))\n",
    "        )\n",
    "        \n",
    "        # Visualization code for KernelExplainer results\n",
    "        # ...\n",
    "        \n",
    "    except Exception as e2:\n",
    "        print(f\"KernelExplainer failed: {str(e2)}\")\n",
    "        \n",
    "        # Final fallback: Try Permutation Importance instead of SHAP\n",
    "        print(\"Trying permutation importance as alternative to SHAP...\")\n",
    "        # Code for permutation importance..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:51:11.284463Z",
     "iopub.status.busy": "2025-04-22T17:51:11.284169Z",
     "iopub.status.idle": "2025-04-22T17:51:11.302964Z",
     "shell.execute_reply": "2025-04-22T17:51:11.302323Z",
     "shell.execute_reply.started": "2025-04-22T17:51:11.284438Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 3. Last resort: Use Permutation Importance as an alternative\n",
    "try:\n",
    "    print(\"Using permutation importance as alternative to SHAP...\")\n",
    "            \n",
    "    from sklearn.inspection import permutation_importance\n",
    "            \n",
    "    # Create a function to compute model accuracy\n",
    "    def model_score(X, y):\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.long).to(device)\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            outputs = best_model(X_tensor)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct = (predicted == y_tensor).sum().item()\n",
    "                \n",
    "        return correct / len(y)\n",
    "            \n",
    "    # Reshape test data for permutation importance\n",
    "    # We'll flatten the sequence dimension to treat each feature separately\n",
    "    X_flat = X_test_seq.reshape(X_test_seq.shape[0], -1)\n",
    "            \n",
    "    # Compute permutation importance (this may take some time)\n",
    "    perm_importance = permutation_importance(\n",
    "        estimator=lambda X: np.argmax(simple_predict(X.reshape(-1, sequence_length, X_test_seq.shape[2])), axis=1),\n",
    "        X=X_flat[:100],  # Use subset for speed\n",
    "        y=y_test_seq[:100],\n",
    "        n_repeats=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "            \n",
    "    # Get feature importances\n",
    "    importances = perm_importance.importances_mean\n",
    "            \n",
    "    # Group importances by original feature (since we flattened the sequence dimension)\n",
    "    feature_importances = np.zeros(X_test_seq.shape[2])\n",
    "    for i in range(X_test_seq.shape[2]):\n",
    "        # Average importance across all timesteps for this feature\n",
    "        indices = np.arange(i, X_flat.shape[1], X_test_seq.shape[2])\n",
    "        feature_importances[i] = np.mean(importances[indices])\n",
    "            \n",
    "    # Sort and plot\n",
    "    feature_indices = np.argsort(-feature_importances)\n",
    "    feature_names = [f\"Feature {i}\" for i in range(X_test_seq.shape[2])]\n",
    "            \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(\n",
    "        y=np.array(feature_names)[feature_indices[:20]],\n",
    "        width=feature_importances[feature_indices[:20]]\n",
    "    )\n",
    "    plt.title('Feature Importance Based on Permutation Importance')\n",
    "    plt.xlabel('Mean Accuracy Decrease')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('permutation_feature_importance.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "            \n",
    "    print(\"Permutation importance analysis completed successfully.\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Permutation importance failed: {str(e)}\")\n",
    "    print(\"All explainability approaches failed. Skipping this phase.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:51:11.304025Z",
     "iopub.status.busy": "2025-04-22T17:51:11.303769Z",
     "iopub.status.idle": "2025-04-22T17:51:11.844441Z",
     "shell.execute_reply": "2025-04-22T17:51:11.843628Z",
     "shell.execute_reply.started": "2025-04-22T17:51:11.304004Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Alternative Model Interpretation: Integrated Gradients\n",
    "print(\"\\n--- Integrated Gradients Analysis ---\")\n",
    "\n",
    "try:\n",
    "    # Implement a simple integrated gradients approach for PyTorch\n",
    "    def integrated_gradients(model, inputs, baseline=None, steps=50):\n",
    "        # If no baseline is provided, use zeros\n",
    "        if baseline is None:\n",
    "            baseline = torch.zeros_like(inputs)\n",
    "        \n",
    "        # Prepare input for gradient calculation\n",
    "        scaled_inputs = [baseline + (float(i) / steps) * (inputs - baseline) for i in range(steps + 1)]\n",
    "        scaled_inputs = torch.cat(scaled_inputs, dim=0)\n",
    "        scaled_inputs.requires_grad_(True)\n",
    "        \n",
    "        # Forward pass\n",
    "        model.eval()\n",
    "        outputs = model(scaled_inputs)\n",
    "        \n",
    "        # Get prediction class\n",
    "        pred_class = outputs[-1].argmax().item()  # Use the last input's prediction\n",
    "        \n",
    "        # Compute gradients for the predicted class\n",
    "        torch.autograd.grad(\n",
    "            outputs=outputs[:, pred_class].sum(), \n",
    "            inputs=scaled_inputs, \n",
    "            create_graph=False, \n",
    "            retain_graph=False\n",
    "        )[0]\n",
    "        \n",
    "        # Average gradients across steps\n",
    "        avg_grads = scaled_inputs.grad.mean(dim=0)\n",
    "        \n",
    "        # Compute integrated gradients: (input - baseline) * avg_grads\n",
    "        integrated_grads = (inputs - baseline) * avg_grads\n",
    "        \n",
    "        return integrated_grads, pred_class\n",
    "    \n",
    "    # Apply to a few test samples\n",
    "    sample_inputs = torch.tensor(X_test_seq[:5], dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Store feature importances\n",
    "    feature_importances = np.zeros(X_test_seq.shape[2])\n",
    "    \n",
    "    for i in range(len(sample_inputs)):\n",
    "        try:\n",
    "            # Compute integrated gradients\n",
    "            ig_attrs, pred_class = integrated_gradients(\n",
    "                model=best_model,\n",
    "                inputs=sample_inputs[i:i+1],\n",
    "                steps=20\n",
    "            )\n",
    "            \n",
    "            # Aggregate importance across sequence dimension\n",
    "            importance = ig_attrs.abs().mean(dim=1).cpu().numpy()\n",
    "            feature_importances += importance\n",
    "            \n",
    "            # Plot heatmap for this sample\n",
    "            plt.figure(figsize=(15, 5))\n",
    "            sns.heatmap(\n",
    "                ig_attrs.abs().cpu().numpy().squeeze(),\n",
    "                cmap='viridis',\n",
    "                yticklabels=False\n",
    "            )\n",
    "            plt.title(f'Integrated Gradients for Sample {i+1}, Predicted Class: {pred_class}')\n",
    "            plt.xlabel('Feature')\n",
    "            plt.ylabel('Sequence Position')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'integrated_gradients_sample_{i+1}.png')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error on sample {i}: {str(e)}\")\n",
    "    \n",
    "    # Plot aggregated feature importance\n",
    "    feature_importances = feature_importances / len(sample_inputs)\n",
    "    feature_indices = np.argsort(-feature_importances)\n",
    "    feature_names = [f\"Feature {i}\" for i in range(X_test_seq.shape[2])]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(\n",
    "        y=np.array(feature_names)[feature_indices[:20]],\n",
    "        width=feature_importances[feature_indices[:20]]\n",
    "    )\n",
    "    plt.title('Feature Importance Based on Integrated Gradients')\n",
    "    plt.xlabel('Mean |Gradient × Input|')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('integrated_gradients_feature_importance.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"Integrated Gradients analysis completed successfully.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Integrated Gradients analysis failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:51:11.845552Z",
     "iopub.status.busy": "2025-04-22T17:51:11.845332Z",
     "iopub.status.idle": "2025-04-22T17:51:32.495580Z",
     "shell.execute_reply": "2025-04-22T17:51:32.494786Z",
     "shell.execute_reply.started": "2025-04-22T17:51:11.845535Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# As a final fallback, implement a simple feature ablation approach\n",
    "try:\n",
    "    print(\"Trying feature ablation approach...\")\n",
    "        \n",
    "    # Function to compute model performance with ablated features\n",
    "    def compute_ablation_score(model, X, y, feature_idx):\n",
    "        # Create copy of data with feature zeroed out\n",
    "        X_ablated = X.copy()\n",
    "        X_ablated[:, :, feature_idx] = 0\n",
    "            \n",
    "        # Convert to tensor\n",
    "        X_tensor = torch.tensor(X_ablated, dtype=torch.float32).to(device)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.long).to(device)\n",
    "            \n",
    "        # Compute predictions\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(X_tensor)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            accuracy = (predictions == y_tensor).sum().item() / len(y)\n",
    "            \n",
    "        return accuracy\n",
    "        \n",
    "    # Get baseline accuracy\n",
    "    X_subset = X_test_seq[:200]  # Use subset for speed\n",
    "    y_subset = y_test_seq[:200]\n",
    "        \n",
    "    X_tensor = torch.tensor(X_subset, dtype=torch.float32).to(device)\n",
    "    y_tensor = torch.tensor(y_subset, dtype=torch.long).to(device)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        outputs = best_model(X_tensor)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        baseline_accuracy = (predictions == y_tensor).sum().item() / len(y_subset)\n",
    "        \n",
    "    # Compute importance by ablating each feature\n",
    "    feature_importances = []\n",
    "    n_features = X_subset.shape[2]\n",
    "        \n",
    "    for i in range(n_features):\n",
    "        ablated_accuracy = compute_ablation_score(best_model, X_subset, y_subset, i)\n",
    "        importance = baseline_accuracy - ablated_accuracy\n",
    "        feature_importances.append(importance)\n",
    "        \n",
    "    # Convert to numpy array\n",
    "    feature_importances = np.array(feature_importances)\n",
    "        \n",
    "    # Plot feature importance\n",
    "    feature_indices = np.argsort(-feature_importances)\n",
    "    feature_names = [f\"Feature {i}\" for i in range(n_features)]\n",
    "        \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(\n",
    "        y=np.array(feature_names)[feature_indices[:20]],\n",
    "        width=feature_importances[feature_indices[:20]]\n",
    "    )\n",
    "    plt.title('Feature Importance Based on Ablation Analysis')\n",
    "    plt.xlabel('Accuracy Decrease When Feature Ablated')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('ablation_feature_importance.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "        \n",
    "    print(\"Feature ablation analysis completed successfully.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Feature ablation failed: {str(e)}\")\n",
    "    print(\"All explainability methods failed. Falling back to model weight analysis only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:51:32.497203Z",
     "iopub.status.busy": "2025-04-22T17:51:32.496448Z",
     "iopub.status.idle": "2025-04-22T17:51:32.954253Z",
     "shell.execute_reply": "2025-04-22T17:51:32.953595Z",
     "shell.execute_reply.started": "2025-04-22T17:51:32.497180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Always run feature importance from model weights as a baseline\n",
    "print(\"\\n--- Feature Importance from Model Weights ---\")\n",
    "\n",
    "try:\n",
    "    # Get the first layer weights of the classifier\n",
    "    classifier_weights = best_model.classifier[0].weight.detach().cpu().numpy()\n",
    "    \n",
    "    # Take absolute values and average across output neurons\n",
    "    feature_importance = np.abs(classifier_weights).mean(axis=0)\n",
    "    \n",
    "    # Map to feature names\n",
    "    feature_names = [f\"Feature {i}\" for i in range(len(feature_importance))]\n",
    "    \n",
    "    # Create DataFrame for easier sorting and plotting\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': feature_importance\n",
    "    })\n",
    "    importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df.head(20))\n",
    "    plt.title('Top 20 Features by Importance (Model Weights)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importance_model_weights.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"Model weight analysis completed successfully.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Model weight analysis failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Phase 10: Feature Importance Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:51:32.955623Z",
     "iopub.status.busy": "2025-04-22T17:51:32.955163Z",
     "iopub.status.idle": "2025-04-22T17:51:33.246098Z",
     "shell.execute_reply": "2025-04-22T17:51:33.245462Z",
     "shell.execute_reply.started": "2025-04-22T17:51:32.955602Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- Feature Importance Analysis ---\")\n",
    "\n",
    "# Get classifier weights from the model\n",
    "def extract_feature_importance(model):\n",
    "    # Extract weights from the first layer of the classifier\n",
    "    classifier_weights = model.classifier[0].weight.detach().cpu().numpy()\n",
    "    # Take the absolute values and average across neurons\n",
    "    feature_importance = np.abs(classifier_weights).mean(axis=0)\n",
    "    return feature_importance\n",
    "\n",
    "# Extract feature importance\n",
    "feature_importance = extract_feature_importance(best_model)\n",
    "\n",
    "# Create feature names (since 'x' is not defined)\n",
    "# Use generic feature names if the original DataFrame is not available\n",
    "feature_names = [f\"Feature_{i}\" for i in range(len(feature_importance))]\n",
    "\n",
    "# Alternatively, if you have a DataFrame with original column names somewhere in your code:\n",
    "# If you used them for preprocessing earlier, you might reference that variable instead\n",
    "# For example, if you have a dataframe_columns variable or can access from a scaler\n",
    "\n",
    "# Create DataFrame with feature importance\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importance\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "feature_importance_df = feature_importance_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(20))\n",
    "plt.title('Top 20 Features by Importance (Model Weights)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance_model_weights.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"\\n--- Top 20 Most Important Features ---\")\n",
    "print(feature_importance_df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Phase 11: Create an Interpretable Visualization of the Model Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:51:33.247116Z",
     "iopub.status.busy": "2025-04-22T17:51:33.246920Z",
     "iopub.status.idle": "2025-04-22T17:51:33.257554Z",
     "shell.execute_reply": "2025-04-22T17:51:33.256832Z",
     "shell.execute_reply.started": "2025-04-22T17:51:33.247100Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- Model Architecture Visualization ---\")\n",
    "\n",
    "def visualize_model_architecture(model):\n",
    "    \"\"\"Create a visualization of the model architecture using Mermaid diagram syntax\"\"\"\n",
    "    model_architecture = \"\"\"\n",
    "    graph TD\n",
    "        A[Input Sequence] --> D[TSMixer]\n",
    "        D --> E[MLP Classifier]\n",
    "        E --> F[Output Classes]\n",
    "        \n",
    "        subgraph \"TSMixer Core\"\n",
    "            D --> D1[Temporal Mixing]\n",
    "            D1 --> D2[Feature Mixing]\n",
    "            D2 --> D3[Layer Norm]\n",
    "        end\n",
    "        \n",
    "        subgraph \"Classifier\"\n",
    "            E --> E1[Linear Layers]\n",
    "            E1 --> E2[Output Layer]\n",
    "        end\n",
    "    \"\"\"\n",
    "    \n",
    "    # Print Mermaid syntax for diagram\n",
    "    print(\"Model Architecture (Mermaid Diagram):\")\n",
    "    print(model_architecture)\n",
    "    \n",
    "    # Create a text summary of the model\n",
    "    print(\"\\nModel Summary:\")\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    \n",
    "    # Print model structure - safer approach that works with any model\n",
    "    print(\"\\nDetailed Model Structure:\")\n",
    "    print(model)\n",
    "    \n",
    "    # Generate simplified layer summary based on the model's structure\n",
    "    print(\"\\nSimplified Layer Summary:\")\n",
    "    \n",
    "    # Find all Linear layers and their sizes to summarize the model structure\n",
    "    linear_layers = []\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            linear_layers.append(f\"{name}: Linear ({module.in_features} → {module.out_features})\")\n",
    "    \n",
    "    for i, layer_info in enumerate(linear_layers):\n",
    "        print(f\"Layer {i+1}: {layer_info}\")\n",
    "\n",
    "# Visualize model architecture\n",
    "visualize_model_architecture(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Phase 12: Conclusion and Results Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:51:33.258633Z",
     "iopub.status.busy": "2025-04-22T17:51:33.258355Z",
     "iopub.status.idle": "2025-04-22T17:51:33.274740Z",
     "shell.execute_reply": "2025-04-22T17:51:33.274137Z",
     "shell.execute_reply.started": "2025-04-22T17:51:33.258608Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- Final Results Summary ---\")\n",
    "\n",
    "label_mapping = {'Normal': 0, 'Attack': 1}\n",
    "\n",
    "summary = {\n",
    "    \"Model\": \"Enhanced TSMixer with Attention\",\n",
    "    \"Best Hyperparameters\": best_params,\n",
    "    \"Test Accuracy\": accuracy,\n",
    "    \"Test Precision\": precision,\n",
    "    \"Test Recall\": recall,\n",
    "    \"Test F1 Score\": f1,\n",
    "    \"Per-Class Accuracy\": {next(k for k, v in label_mapping.items() if v == cls): acc \n",
    "                          for cls, acc in per_class_accuracy.items()}\n",
    "}\n",
    "\n",
    "print(\"Final Results Summary:\")\n",
    "pp.pprint(summary)\n",
    "\n",
    "print(\"\\nTraining completed successfully. All results and visualizations have been saved.\")\n",
    "\n",
    "# Final clean up and saving results to JSON\n",
    "import json\n",
    "\n",
    "# Convert numpy values to Python native types for JSON serialization\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, np.float32) or isinstance(obj, np.float64):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.int32) or isinstance(obj, np.int64):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_serializable(item) for item in obj]\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# Save final results\n",
    "serializable_summary = convert_to_serializable(summary)\n",
    "with open('final_results_summary.json', 'w') as f:\n",
    "    json.dump(serializable_summary, f, indent=4)\n",
    "\n",
    "print(\"\\nResults saved to 'final_results_summary.json'\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7218761,
     "sourceId": 11511943,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
